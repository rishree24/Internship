{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.common.exceptions import ElementNotInteractableException\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "import time\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Scrape the details of most viewed videos on YouTube from Wikipedia:\n",
    "\n",
    "Url= https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\n",
    "\n",
    "You need to find following details:\n",
    "\n",
    "A) Rank\n",
    "\n",
    "B) Name\n",
    "\n",
    "C) Artist\n",
    "\n",
    "D) Upload date\n",
    "\n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to web driver\n",
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the website to driver\n",
    "driver.get('https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos')\n",
    "\n",
    "#When we run this line, automatically the webpage will be opened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Video Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Views(Billions)</th>\n",
       "      <th>Upload Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>7,046,700,000</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>November 2, 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>2,993,700,000</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>August 4, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>2,894,000,000</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>July 10, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Psy</td>\n",
       "      <td>803,700,000</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>November 24, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>245,400,000</td>\n",
       "      <td>February 19, 2010</td>\n",
       "      <td>July 16, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Lady Gaga</td>\n",
       "      <td>178,400,000</td>\n",
       "      <td>November 24, 2009</td>\n",
       "      <td>April 14, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>HDCYT</td>\n",
       "      <td>128,900,000</td>\n",
       "      <td>May 22, 2007</td>\n",
       "      <td>October 25, 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Judson Laipply</td>\n",
       "      <td>118,900,000</td>\n",
       "      <td>April 6, 2006</td>\n",
       "      <td>May 2, 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>RCA Records</td>\n",
       "      <td>92,600,000</td>\n",
       "      <td>February 27, 2007</td>\n",
       "      <td>July 17, 2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Judson Laipply</td>\n",
       "      <td>78,400,000</td>\n",
       "      <td>April 6, 2006</td>\n",
       "      <td>March 15, 2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>CLARUSBARTEL72</td>\n",
       "      <td>76,600,000</td>\n",
       "      <td>April 9, 2007</td>\n",
       "      <td>March 1, 2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Judson Laipply</td>\n",
       "      <td>10,600,000</td>\n",
       "      <td>April 6, 2006</td>\n",
       "      <td>May 19, 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Smosh</td>\n",
       "      <td>4,300,000</td>\n",
       "      <td>November 28, 2005</td>\n",
       "      <td>March 12, 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>eggtea</td>\n",
       "      <td>2,700,000</td>\n",
       "      <td>January 31, 2006</td>\n",
       "      <td>February 18, 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>mugenized</td>\n",
       "      <td>3,400,000</td>\n",
       "      <td>December 1, 2005</td>\n",
       "      <td>January 21, 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>youtubedude</td>\n",
       "      <td>2,300,000</td>\n",
       "      <td>December 18, 2005</td>\n",
       "      <td>January 9, 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Nikesoccer</td>\n",
       "      <td>255,000</td>\n",
       "      <td>October 21, 2005</td>\n",
       "      <td>October 31, 2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>larfus</td>\n",
       "      <td>247,000</td>\n",
       "      <td>October 5, 2005</td>\n",
       "      <td>October 29, 2005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Rank                                   Video Name         Artist  \\\n",
       "0      1  Pinkfong Baby Shark - Kids' Songs & Stories  7,046,700,000   \n",
       "1      2                                   Luis Fonsi  2,993,700,000   \n",
       "2      3                                  Wiz Khalifa  2,894,000,000   \n",
       "3      4                                          Psy    803,700,000   \n",
       "4      5                                Justin Bieber    245,400,000   \n",
       "5      6                                    Lady Gaga    178,400,000   \n",
       "6      7                                        HDCYT    128,900,000   \n",
       "7      8                               Judson Laipply    118,900,000   \n",
       "8      9                                  RCA Records     92,600,000   \n",
       "9     10                               Judson Laipply     78,400,000   \n",
       "10    11                               CLARUSBARTEL72     76,600,000   \n",
       "11    12                               Judson Laipply     10,600,000   \n",
       "12    13                                        Smosh      4,300,000   \n",
       "13    14                                       eggtea      2,700,000   \n",
       "14    15                                    mugenized      3,400,000   \n",
       "15    16                                  youtubedude      2,300,000   \n",
       "16    17                                   Nikesoccer        255,000   \n",
       "17    18                                       larfus        247,000   \n",
       "\n",
       "      Views(Billions)        Upload Date  \n",
       "0       June 17, 2016   November 2, 2020  \n",
       "1    January 12, 2017     August 4, 2017  \n",
       "2       April 6, 2015      July 10, 2017  \n",
       "3       July 15, 2012  November 24, 2012  \n",
       "4   February 19, 2010      July 16, 2010  \n",
       "5   November 24, 2009     April 14, 2010  \n",
       "6        May 22, 2007   October 25, 2009  \n",
       "7       April 6, 2006        May 2, 2009  \n",
       "8   February 27, 2007      July 17, 2008  \n",
       "9       April 6, 2006     March 15, 2008  \n",
       "10      April 9, 2007      March 1, 2008  \n",
       "11      April 6, 2006       May 19, 2006  \n",
       "12  November 28, 2005     March 12, 2006  \n",
       "13   January 31, 2006  February 18, 2006  \n",
       "14   December 1, 2005   January 21, 2006  \n",
       "15  December 18, 2005    January 9, 2006  \n",
       "16   October 21, 2005   October 31, 2005  \n",
       "17    October 5, 2005   October 29, 2005  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating the empty lists to store the scraped data\n",
    "Rank=[]\n",
    "Name=[]\n",
    "Artist=[]\n",
    "Views=[]\n",
    "Upload_Date=[]\n",
    "\n",
    "#As we need only the first 30 details, we will iterate only for the first 30 data\n",
    "#Scrapping the details of the Rank of the video\n",
    "rank=driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter']/tbody/tr/td[1]\")\n",
    "for index, value in enumerate(rank[:30], start=1):\n",
    "    Rank.append(index)\n",
    "\n",
    "# Scrapping the details of the video name\n",
    "video=driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter']/tbody/tr/td[2]\")\n",
    "for i in video[:30]:\n",
    "    Name.append(i.text)\n",
    "    \n",
    "# Scrapping the details of the Artist name\n",
    "artist=driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter']/tbody/tr/td[3]\")\n",
    "for i in artist[:30]:\n",
    "    Artist.append(i.text)\n",
    "    \n",
    "# Scrapping the details of the views information\n",
    "views=driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter']/tbody/tr/td[4]\")\n",
    "for i in views[:30]:\n",
    "    Views.append(i.text)\n",
    "    \n",
    "# Scrapping the details of the upload date\n",
    "date=driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter']/tbody/tr/td[5]\")\n",
    "for i in date[:30]:\n",
    "    Upload_Date.append(i.text)\n",
    "\n",
    "# Creating a dataframe for storing the scraped data\n",
    "Yt_data=pd.DataFrame({})\n",
    "Yt_data['Rank']=Rank\n",
    "Yt_data['Video Name']=Name\n",
    "Yt_data['Artist']=Artist\n",
    "Yt_data['Views(Billions)']=Views\n",
    "Yt_data['Upload Date']=Upload_Date\n",
    "\n",
    "Yt_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Closing the driver\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Scrape the details team India’s international fixtures from bcci.tv.\n",
    "\n",
    "Url = https://www.bcci.tv/\n",
    "\n",
    "You need to find following details:\n",
    "\n",
    "A) Match title (I.e. 1st ODI)\n",
    "\n",
    "B) Series\n",
    "\n",
    "C) Place\n",
    "\n",
    "D) Date\n",
    "\n",
    "E) Time\n",
    "\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to web driver\n",
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the website to driver\n",
    "driver.get('https://www.bcci.tv/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking international fixture section\n",
    "international=driver.find_element(By.XPATH,'/html/body/header/div[3]/div[2]/ul/div[1]/a[2]')\n",
    "driver.get(international.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match name</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5th Test</td>\n",
       "      <td>ENGLAND TOUR OF INDIA 2023-24</td>\n",
       "      <td>Himachal Pradesh Cricket Association Stadium, ...</td>\n",
       "      <td>7 MARCH, 2024</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1st T20I</td>\n",
       "      <td>INDIA TOUR OF ZIMBABWE 2024</td>\n",
       "      <td>Harare Sports Club, Harare</td>\n",
       "      <td>6 JULY, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2nd T20I</td>\n",
       "      <td>INDIA TOUR OF ZIMBABWE 2024</td>\n",
       "      <td>Harare Sports Club, Harare</td>\n",
       "      <td>7 JULY, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3rd T20I</td>\n",
       "      <td>INDIA TOUR OF ZIMBABWE 2024</td>\n",
       "      <td>Harare Sports Club, Harare</td>\n",
       "      <td>10 JULY, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4th T20I</td>\n",
       "      <td>INDIA TOUR OF ZIMBABWE 2024</td>\n",
       "      <td>Harare Sports Club, Harare</td>\n",
       "      <td>13 JULY, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5th T20I</td>\n",
       "      <td>INDIA TOUR OF ZIMBABWE 2024</td>\n",
       "      <td>Harare Sports Club, Harare</td>\n",
       "      <td>14 JULY, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Match name                         Series  \\\n",
       "0   5th Test  ENGLAND TOUR OF INDIA 2023-24   \n",
       "1   1st T20I    INDIA TOUR OF ZIMBABWE 2024   \n",
       "2   2nd T20I    INDIA TOUR OF ZIMBABWE 2024   \n",
       "3   3rd T20I    INDIA TOUR OF ZIMBABWE 2024   \n",
       "4   4th T20I    INDIA TOUR OF ZIMBABWE 2024   \n",
       "5   5th T20I    INDIA TOUR OF ZIMBABWE 2024   \n",
       "\n",
       "                                               Place           Date  \\\n",
       "0  Himachal Pradesh Cricket Association Stadium, ...  7 MARCH, 2024   \n",
       "1                         Harare Sports Club, Harare   6 JULY, 2024   \n",
       "2                         Harare Sports Club, Harare   7 JULY, 2024   \n",
       "3                         Harare Sports Club, Harare  10 JULY, 2024   \n",
       "4                         Harare Sports Club, Harare  13 JULY, 2024   \n",
       "5                         Harare Sports Club, Harare  14 JULY, 2024   \n",
       "\n",
       "          Time  \n",
       "0  9:30 AM IST  \n",
       "1  8:00 PM IST  \n",
       "2  8:00 PM IST  \n",
       "3  8:00 PM IST  \n",
       "4  8:00 PM IST  \n",
       "5  8:00 PM IST  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating empty lists for storing the scrapped data\n",
    "Match=[]\n",
    "Series=[]\n",
    "Place=[]\n",
    "Date=[]\n",
    "Time=[]\n",
    "\n",
    "name_elements = WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_all_elements_located((By.XPATH, '//div[@class=\"match-card-top\"]/div/div/span[1]'))\n",
    ")\n",
    "series_elements = WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_all_elements_located((By.XPATH, '//h5[@class=\"match-tournament-name ng-binding\"]'))\n",
    ")\n",
    "place_elements = WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_all_elements_located((By.XPATH, '//div[@class=\"match-place ng-scope\"]'))\n",
    ")\n",
    "date_elements = WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_all_elements_located((By.XPATH, '//div[@class=\"match-date-info\"]/div[1]'))\n",
    ")\n",
    "time_elements = WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_all_elements_located((By.XPATH, '//div[@class=\"match-time no-margin ng-binding\"]'))\n",
    ")\n",
    "\n",
    "#Scrapping the data having the match name\n",
    "name=driver.find_elements(By.XPATH,'//div[@class=\"match-card-top\"]/div/div/span[1]')\n",
    "for i in name:\n",
    "    Match.append(i.text)\n",
    "\n",
    "#Scrapping the data having the series name\n",
    "series=driver.find_elements(By.XPATH,'//h5[@class=\"match-tournament-name ng-binding\"]')\n",
    "for i in series:\n",
    "    Series.append(i.text)\n",
    "    \n",
    "#Scrapping the data having the place of match\n",
    "place=driver.find_elements(By.XPATH,'//div[@class=\"match-place ng-scope\"]')\n",
    "for i in place:\n",
    "    Place.append(i.text)\n",
    "    \n",
    "#Scrapping the data having the match date\n",
    "date=driver.find_elements(By.XPATH,'//div[@class=\"match-date-info\"]/div[1]')  #Only date\n",
    "for i in range(len(date)):\n",
    "    Date.append(date[i].text)  #Appending date and month texts together\n",
    "    \n",
    "#Scrapping the data having match time\n",
    "time=driver.find_elements(By.XPATH,'//div[@class=\"match-time no-margin ng-binding\"]')\n",
    "for i in time:\n",
    "    Time.append(i.text)\n",
    "\n",
    "#Creating a Dataframe for the scrapped data\n",
    "fixtures=pd.DataFrame({})\n",
    "fixtures['Match name']=Match\n",
    "fixtures['Series']=Series\n",
    "fixtures['Place']=Place\n",
    "fixtures['Date']=Date\n",
    "fixtures['Time']=Time\n",
    "fixtures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Closing the driver\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "\n",
    "Url = http://statisticstimes.com/\n",
    "\n",
    "You have to find following details:\n",
    "\n",
    "A) Rank\n",
    "\n",
    "B) State\n",
    "\n",
    "C) GSDP(19-20)\n",
    "\n",
    "D) GSDP(18-19)\n",
    "\n",
    "E) Share(18-19)\n",
    "\n",
    "F) GDP($ billion)\n",
    "\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to web driver\n",
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening Wikipedia webpage\n",
    "url='https://www.statisticstimes.com/'\n",
    "driver.get(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Empty lists\n",
    "Rank =[]\n",
    "State =[]\n",
    "GDSP_19_20=[]\n",
    "GDSP_18_19 =[]\n",
    "Share =[]\n",
    "GDP =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking on India under ecomony section\n",
    "India=driver.find_element(By.XPATH,'//div[@class=\"dropdown\"][2]/div/a[3]')\n",
    "try:\n",
    "    India.click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(India.get_attribute('href'))\n",
    "    \n",
    "\n",
    "\n",
    "# Clicking Indian State GDP\n",
    "state = driver.find_element(By.XPATH,'//ul[@style=\"list-style-type:none;margin-left:20px;\"]/li[1]/a')\n",
    "try:\n",
    "    state.click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(state.get_attribute('href'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Rank via Xpath\n",
    "try:\n",
    "    rank=driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]/tbody/tr/td[1]')\n",
    "    for i in rank:\n",
    "        Rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Rank.append('NA')\n",
    "    \n",
    "# Extracting state name via Xpath\n",
    "try:\n",
    "    state=driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]/tbody/tr/td[2]')\n",
    "    for i in state:\n",
    "        State.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    State.append('NA')\n",
    "    \n",
    "# Extracting GDSP 19-20 via Xpath\n",
    "try:\n",
    "    gdsp_19_20=driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]/tbody/tr/td[3]')\n",
    "    for i in gdsp_19_20:\n",
    "        GDSP_19_20.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GDSP_19_20.append('NA')\n",
    "    \n",
    "# Extracting GDSP 18-19 via Xpath\n",
    "try:\n",
    "    gdsp_18_19=driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]/tbody/tr/td[4]')\n",
    "    for i in gdsp_18_19:\n",
    "        GDSP_18_19.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GDSP_18_19.append('NA')\n",
    "    \n",
    "# Extracting share in billons via Xpath\n",
    "try:\n",
    "    share=driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]/tbody/tr/td[5]')\n",
    "    for i in share:\n",
    "        Share.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Share.append('NA')\n",
    "\n",
    "# Extracting GDP via Xpath\n",
    "try:\n",
    "    gdp=driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]/tbody/tr/td[6]')\n",
    "    for i in gdp:\n",
    "        GDP.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GDP.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mState-wise GDP of India :\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GDSP 19-20</th>\n",
       "      <th>GDSP 18-19</th>\n",
       "      <th>Share</th>\n",
       "      <th>GDP (in Billions)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>3,108,022</td>\n",
       "      <td>13.24%</td>\n",
       "      <td>417.163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>2,364,514</td>\n",
       "      <td>2,071,286</td>\n",
       "      <td>8.82%</td>\n",
       "      <td>278.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>2,257,575</td>\n",
       "      <td>1,974,532</td>\n",
       "      <td>8.41%</td>\n",
       "      <td>265.024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>2,241,368</td>\n",
       "      <td>1,962,725</td>\n",
       "      <td>8.36%</td>\n",
       "      <td>263.440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>1,937,066</td>\n",
       "      <td>8.25%</td>\n",
       "      <td>259.996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,554,992</td>\n",
       "      <td>1,363,926</td>\n",
       "      <td>5.81%</td>\n",
       "      <td>183.068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>1,413,620</td>\n",
       "      <td>1,218,193</td>\n",
       "      <td>5.19%</td>\n",
       "      <td>163.507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>1,322,821</td>\n",
       "      <td>1,136,137</td>\n",
       "      <td>4.84%</td>\n",
       "      <td>152.494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>1,317,728</td>\n",
       "      <td>1,133,837</td>\n",
       "      <td>4.83%</td>\n",
       "      <td>152.185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>1,313,391</td>\n",
       "      <td>1,128,907</td>\n",
       "      <td>4.81%</td>\n",
       "      <td>151.523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>-</td>\n",
       "      <td>932,470</td>\n",
       "      <td>3.97%</td>\n",
       "      <td>125.157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>1,043,759</td>\n",
       "      <td>904,642</td>\n",
       "      <td>3.85%</td>\n",
       "      <td>121.422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>994,154</td>\n",
       "      <td>870,665</td>\n",
       "      <td>3.71%</td>\n",
       "      <td>116.862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>774,869</td>\n",
       "      <td>670,881</td>\n",
       "      <td>2.86%</td>\n",
       "      <td>90.047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>751,396</td>\n",
       "      <td>650,302</td>\n",
       "      <td>2.77%</td>\n",
       "      <td>87.284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>673,107</td>\n",
       "      <td>614,227</td>\n",
       "      <td>2.62%</td>\n",
       "      <td>82.442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>493,167</td>\n",
       "      <td>412,612</td>\n",
       "      <td>1.76%</td>\n",
       "      <td>55.381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>457,608</td>\n",
       "      <td>406,416</td>\n",
       "      <td>1.73%</td>\n",
       "      <td>54.550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>393,722</td>\n",
       "      <td>358,863</td>\n",
       "      <td>1.53%</td>\n",
       "      <td>48.167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>302,621</td>\n",
       "      <td>272,159</td>\n",
       "      <td>1.16%</td>\n",
       "      <td>36.530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir-UT</td>\n",
       "      <td>227,927</td>\n",
       "      <td>199,917</td>\n",
       "      <td>0.85%</td>\n",
       "      <td>26.833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>195,405</td>\n",
       "      <td>176,269</td>\n",
       "      <td>0.75%</td>\n",
       "      <td>23.659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>-</td>\n",
       "      <td>82,604</td>\n",
       "      <td>0.35%</td>\n",
       "      <td>11.087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>72,636</td>\n",
       "      <td>62,550</td>\n",
       "      <td>0.27%</td>\n",
       "      <td>8.396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>-</td>\n",
       "      <td>45,635</td>\n",
       "      <td>0.19%</td>\n",
       "      <td>6.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>-</td>\n",
       "      <td>44,238</td>\n",
       "      <td>0.19%</td>\n",
       "      <td>5.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>42,697</td>\n",
       "      <td>38,785</td>\n",
       "      <td>0.17%</td>\n",
       "      <td>5.206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>42,756</td>\n",
       "      <td>37,557</td>\n",
       "      <td>0.16%</td>\n",
       "      <td>5.041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>-</td>\n",
       "      <td>36,594</td>\n",
       "      <td>0.16%</td>\n",
       "      <td>4.912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>-</td>\n",
       "      <td>35,124</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>-</td>\n",
       "      <td>31,913</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>-</td>\n",
       "      <td>27,824</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>10,371</td>\n",
       "      <td>0.04%</td>\n",
       "      <td>1.392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State GDSP 19-20 GDSP 18-19   Share  \\\n",
       "0     1                Maharashtra          -  3,108,022  13.24%   \n",
       "1     2                 Tamil Nadu  2,364,514  2,071,286   8.82%   \n",
       "2     3              Uttar Pradesh  2,257,575  1,974,532   8.41%   \n",
       "3     4                  Karnataka  2,241,368  1,962,725   8.36%   \n",
       "4     5                    Gujarat          -  1,937,066   8.25%   \n",
       "5     6                West Bengal  1,554,992  1,363,926   5.81%   \n",
       "6     7                  Rajasthan  1,413,620  1,218,193   5.19%   \n",
       "7     8             Madhya Pradesh  1,322,821  1,136,137   4.84%   \n",
       "8     9             Andhra Pradesh  1,317,728  1,133,837   4.83%   \n",
       "9    10                  Telangana  1,313,391  1,128,907   4.81%   \n",
       "10   11                     Kerala          -    932,470   3.97%   \n",
       "11   12                      Delhi  1,043,759    904,642   3.85%   \n",
       "12   13                    Haryana    994,154    870,665   3.71%   \n",
       "13   14                     Odisha    774,869    670,881   2.86%   \n",
       "14   15                      Bihar    751,396    650,302   2.77%   \n",
       "15   16                     Punjab    673,107    614,227   2.62%   \n",
       "16   17                      Assam    493,167    412,612   1.76%   \n",
       "17   18               Chhattisgarh    457,608    406,416   1.73%   \n",
       "18   19                  Jharkhand    393,722    358,863   1.53%   \n",
       "19   20                Uttarakhand    302,621    272,159   1.16%   \n",
       "20   21         Jammu & Kashmir-UT    227,927    199,917   0.85%   \n",
       "21   22           Himachal Pradesh    195,405    176,269   0.75%   \n",
       "22   23                        Goa          -     82,604   0.35%   \n",
       "23   24                    Tripura     72,636     62,550   0.27%   \n",
       "24   25                 Chandigarh          -     45,635   0.19%   \n",
       "25   26                 Puducherry          -     44,238   0.19%   \n",
       "26   27                  Meghalaya     42,697     38,785   0.17%   \n",
       "27   28                     Sikkim     42,756     37,557   0.16%   \n",
       "28   29                    Manipur          -     36,594   0.16%   \n",
       "29   30          Arunachal Pradesh          -     35,124   0.15%   \n",
       "30   31                   Nagaland          -     31,913   0.14%   \n",
       "31   32                    Mizoram          -     27,824   0.12%   \n",
       "32   33  Andaman & Nicobar Islands          -     10,371   0.04%   \n",
       "\n",
       "   GDP (in Billions)  \n",
       "0            417.163  \n",
       "1            278.011  \n",
       "2            265.024  \n",
       "3            263.440  \n",
       "4            259.996  \n",
       "5            183.068  \n",
       "6            163.507  \n",
       "7            152.494  \n",
       "8            152.185  \n",
       "9            151.523  \n",
       "10           125.157  \n",
       "11           121.422  \n",
       "12           116.862  \n",
       "13            90.047  \n",
       "14            87.284  \n",
       "15            82.442  \n",
       "16            55.381  \n",
       "17            54.550  \n",
       "18            48.167  \n",
       "19            36.530  \n",
       "20            26.833  \n",
       "21            23.659  \n",
       "22            11.087  \n",
       "23             8.396  \n",
       "24             6.125  \n",
       "25             5.938  \n",
       "26             5.206  \n",
       "27             5.041  \n",
       "28             4.912  \n",
       "29             4.714  \n",
       "30             4.283  \n",
       "31             3.735  \n",
       "32             1.392  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe for scrap data\n",
    "Statewise_GDP=pd.DataFrame({'Rank':Rank,'State':State,'GDSP 19-20':GDSP_19_20,'GDSP 18-19':GDSP_18_19,\n",
    "                            'Share':Share,'GDP (in Billions)':GDP})\n",
    "print('\\033[1m'+'State-wise GDP of India :'+'\\033[0m')\n",
    "Statewise_GDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Closing the driver\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.Scrape the details of trending repositories on Github.com.\n",
    "\n",
    "Url = https://github.com/\n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "A) Repository title\n",
    "\n",
    "B) Repository description\n",
    "\n",
    "C) Contributors count\n",
    "\n",
    "D) Language used\n",
    "\n",
    "Note: - From the home page you have to click on the trending option from Explore menu through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to web driver\n",
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 24 25 25\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Contributors count</th>\n",
       "      <th>Language used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cloudflare / pingora</td>\n",
       "      <td>A library for building fast, reliable and evol...</td>\n",
       "      <td></td>\n",
       "      <td>Rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lissy93 / web-check</td>\n",
       "      <td>🕵️‍♂️ All-in-one OSINT tool for analysing any ...</td>\n",
       "      <td></td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>polyfillpolyfill / polyfill-service</td>\n",
       "      <td>Automatic polyfill service.</td>\n",
       "      <td></td>\n",
       "      <td>Built by</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HumanAIGC / EMO</td>\n",
       "      <td>A curated list of free courses &amp; certifications.</td>\n",
       "      <td></td>\n",
       "      <td>Built by</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cloudcommunity / Free-Certifications</td>\n",
       "      <td>Nintendo Switch emulator</td>\n",
       "      <td></td>\n",
       "      <td>Built by</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>yuzu-emu / yuzu</td>\n",
       "      <td>18 Lessons, Get Started Building with Generati...</td>\n",
       "      <td></td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>microsoft / generative-ai-for-beginners</td>\n",
       "      <td>Animate Anyone: Consistent and Controllable Im...</td>\n",
       "      <td></td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HumanAIGC / AnimateAnyone</td>\n",
       "      <td>Implementation of \"BitNet: Scaling 1-bit Trans...</td>\n",
       "      <td></td>\n",
       "      <td>Built by</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>kyegomez / BitNet</td>\n",
       "      <td>Windows in a Docker container.</td>\n",
       "      <td></td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dockur / windows</td>\n",
       "      <td>Rust full node implementation of the Fuel v2 p...</td>\n",
       "      <td></td>\n",
       "      <td>Shell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>FuelLabs / fuel-core</td>\n",
       "      <td>🔥Highlighting the top ML papers every week.</td>\n",
       "      <td></td>\n",
       "      <td>Rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>dair-ai / ML-Papers-of-the-Week</td>\n",
       "      <td>👩🏿‍💻👨🏾‍💻👩🏼‍💻👨🏽‍💻👩🏻‍💻中国独立开发者项目列表 -- 分享大家都在做什么</td>\n",
       "      <td></td>\n",
       "      <td>Built by</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1c7 / chinese-independent-developer</td>\n",
       "      <td>This repository is the future home of the Rive...</td>\n",
       "      <td></td>\n",
       "      <td>Built by</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>memorysafety / river</td>\n",
       "      <td>Turns Data and AI algorithms into production-r...</td>\n",
       "      <td></td>\n",
       "      <td>Built by</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Avaiga / taipy</td>\n",
       "      <td>A one stop repository for generative AI resear...</td>\n",
       "      <td></td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>aishwaryanr / awesome-generative-ai-guide</td>\n",
       "      <td>Wazuh - The Open Source Security Platform. Uni...</td>\n",
       "      <td></td>\n",
       "      <td>Built by</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>wazuh / wazuh</td>\n",
       "      <td>High-quality multi-lingual text-to-speech libr...</td>\n",
       "      <td></td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>myshell-ai / MeloTTS</td>\n",
       "      <td>🔥 全面ESM+Vue3+Vite+Element-Plus+TypeScript编写的一款...</td>\n",
       "      <td></td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>pure-admin / vue-pure-admin</td>\n",
       "      <td>Python packaging and dependency management mad...</td>\n",
       "      <td></td>\n",
       "      <td>Vue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>python-poetry / poetry</td>\n",
       "      <td>Large-scale Self-supervised Pre-training Acros...</td>\n",
       "      <td></td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>microsoft / unilm</td>\n",
       "      <td>🚀 A robust, performance-focused, and full-feat...</td>\n",
       "      <td></td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Repository title  \\\n",
       "0                        cloudflare / pingora   \n",
       "1                         Lissy93 / web-check   \n",
       "2         polyfillpolyfill / polyfill-service   \n",
       "3                             HumanAIGC / EMO   \n",
       "4        cloudcommunity / Free-Certifications   \n",
       "5                             yuzu-emu / yuzu   \n",
       "6     microsoft / generative-ai-for-beginners   \n",
       "7                   HumanAIGC / AnimateAnyone   \n",
       "8                           kyegomez / BitNet   \n",
       "9                            dockur / windows   \n",
       "10                       FuelLabs / fuel-core   \n",
       "11            dair-ai / ML-Papers-of-the-Week   \n",
       "12        1c7 / chinese-independent-developer   \n",
       "13                       memorysafety / river   \n",
       "14                             Avaiga / taipy   \n",
       "15  aishwaryanr / awesome-generative-ai-guide   \n",
       "16                              wazuh / wazuh   \n",
       "17                       myshell-ai / MeloTTS   \n",
       "18                pure-admin / vue-pure-admin   \n",
       "19                     python-poetry / poetry   \n",
       "20                          microsoft / unilm   \n",
       "\n",
       "                                          Description Contributors count  \\\n",
       "0   A library for building fast, reliable and evol...                      \n",
       "1   🕵️‍♂️ All-in-one OSINT tool for analysing any ...                      \n",
       "2                         Automatic polyfill service.                      \n",
       "3    A curated list of free courses & certifications.                      \n",
       "4                            Nintendo Switch emulator                      \n",
       "5   18 Lessons, Get Started Building with Generati...                      \n",
       "6   Animate Anyone: Consistent and Controllable Im...                      \n",
       "7   Implementation of \"BitNet: Scaling 1-bit Trans...                      \n",
       "8                      Windows in a Docker container.                      \n",
       "9   Rust full node implementation of the Fuel v2 p...                      \n",
       "10        🔥Highlighting the top ML papers every week.                      \n",
       "11       👩🏿‍💻👨🏾‍💻👩🏼‍💻👨🏽‍💻👩🏻‍💻中国独立开发者项目列表 -- 分享大家都在做什么                      \n",
       "12  This repository is the future home of the Rive...                      \n",
       "13  Turns Data and AI algorithms into production-r...                      \n",
       "14  A one stop repository for generative AI resear...                      \n",
       "15  Wazuh - The Open Source Security Platform. Uni...                      \n",
       "16  High-quality multi-lingual text-to-speech libr...                      \n",
       "17  🔥 全面ESM+Vue3+Vite+Element-Plus+TypeScript编写的一款...                      \n",
       "18  Python packaging and dependency management mad...                      \n",
       "19  Large-scale Self-supervised Pre-training Acros...                      \n",
       "20  🚀 A robust, performance-focused, and full-feat...                      \n",
       "\n",
       "       Language used  \n",
       "0               Rust  \n",
       "1         TypeScript  \n",
       "2           Built by  \n",
       "3           Built by  \n",
       "4           Built by  \n",
       "5                C++  \n",
       "6   Jupyter Notebook  \n",
       "7           Built by  \n",
       "8             Python  \n",
       "9              Shell  \n",
       "10              Rust  \n",
       "11          Built by  \n",
       "12          Built by  \n",
       "13          Built by  \n",
       "14            Python  \n",
       "15          Built by  \n",
       "16                 C  \n",
       "17            Python  \n",
       "18               Vue  \n",
       "19            Python  \n",
       "20            Python  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to wait for an element to be present in the DOM\n",
    "def wait_for_element(driver, xpath):\n",
    "    return WebDriverWait(driver, 10).until(EC.presence_of_all_elements_located((By.XPATH, xpath)))\n",
    "\n",
    "# Getting the website to driver\n",
    "driver.get('https://github.com/')\n",
    "\n",
    "# Clicking explore tab and trending option using exception\n",
    "Open_Source = driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]')\n",
    "try:\n",
    "    Open_Source.click()\n",
    "except ElementNotInteractableException as e:\n",
    "    driver.get(Open_Source.get_attribute('href'))\n",
    "\n",
    "trending = driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/div/div[3]/ul/li[2]/a')\n",
    "try:\n",
    "    trending.click()\n",
    "except ElementNotInteractableException as e:\n",
    "    driver.get(trending.get_attribute('href'))\n",
    "\n",
    "# Wait for the elements to be present in the DOM\n",
    "title_elements = wait_for_element(driver, '//h2[@class=\"h3 lh-condensed\"]/a')\n",
    "desc_elements = wait_for_element(driver, '//p[@class=\"col-9 color-fg-muted my-1 pr-4\"]')\n",
    "count_elements = wait_for_element(driver, '//div[@class=\"f6 color-fg-muted mt-2\"]/span/a[1]')\n",
    "lang_elements = wait_for_element(driver, '//div[@class=\"f6 color-fg-muted mt-2\"]/span[1]')\n",
    "\n",
    "# Scrapping the data having the repository title\n",
    "rep_title = [i.text for i in title_elements]\n",
    "\n",
    "# Scrapping the data having the repository description\n",
    "rep_desc = [i.text for i in desc_elements]\n",
    "\n",
    "# Scrapping the data having the contributors count\n",
    "Count = [i.text for i in count_elements]\n",
    "\n",
    "# Scrapping the data having the language used\n",
    "Lang = [i.text if i.text is not None else 'Not Available' for i in lang_elements]\n",
    "\n",
    "# Checking out the length of scrapped data\n",
    "print(len(rep_title), len(rep_desc), len(Count), len(Lang))\n",
    "\n",
    "# Creating a dataframe for the scrapped data\n",
    "rep_title = rep_title[:21]\n",
    "rep_desc = rep_desc[:21]\n",
    "Count = Count[:21]\n",
    "Lang = Lang[:21]\n",
    "\n",
    "github = pd.DataFrame({\n",
    "    'Repository title': rep_title,\n",
    "    'Description': rep_desc,\n",
    "    'Contributors count': Count,\n",
    "    'Language used': Lang\n",
    "})\n",
    "\n",
    "# Print the DataFrame\n",
    "github\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Closing the driver\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.Scrape the details of top 100 songs on billiboard.com.\n",
    "\n",
    "Url = https://www.billboard.com/\n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "A) Song name\n",
    "\n",
    "B) Artist name\n",
    "\n",
    "C) Last week rank\n",
    "\n",
    "D) Peak rank\n",
    "\n",
    "E) Weeks on board\n",
    "\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to web driver\n",
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the website to driver\n",
    "driver.get('https://www.billboard.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking charts and then hot100 option\n",
    "charts=driver.find_element(By.XPATH,\"/html/body/div[3]/header/div/div[2]/div/div/div[2]/div[2]/div/div/nav/ul/li[1]/a\")\n",
    "try:\n",
    "    charts.click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(charts.get_attribute('href'))\n",
    "    \n",
    "hot_100=driver.find_element(By.XPATH,\"/html/body/div[3]/main/div[2]/div[1]/div[1]/div/div/div[1]/div/div[2]/span/a\")\n",
    "try:\n",
    "    hot_100.click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(hot_100.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty lists for storing the scrapped data\n",
    "Song=[]\n",
    "Artist=[]\n",
    "Lastweek=[]\n",
    "Peak=[]\n",
    "Weeks_on_board=[]\n",
    "\n",
    "#Scrapping the data having the song name\n",
    "song=driver.find_elements(By.XPATH,'//div[@class=\"o-chart-results-list-row-container\"]/ul/li[4]/ul/li/h3')\n",
    "for i in song:\n",
    "    Song.append(i.text)\n",
    "    \n",
    "#Scrapping the data having the artist name\n",
    "artist=driver.find_elements(By.XPATH,'//div[@class=\"o-chart-results-list-row-container\"]/ul/li[4]/ul/li[1]/span')\n",
    "for i in artist:\n",
    "    Artist.append(i.text)\n",
    "    \n",
    "#Scrapping the data having the last week rank\n",
    "last_week=driver.find_elements(By.XPATH,'//div[@class=\"o-chart-results-list-row-container\"]/ul/li[4]/ul/li[4]/span')\n",
    "for i in last_week:\n",
    "    if i.text is None:\n",
    "        Lastweek.append('-')\n",
    "    else:\n",
    "        Lastweek.append(i.text)\n",
    "        \n",
    "#Scrapping the data having the peak rank\n",
    "peak=driver.find_elements(By.XPATH,'//div[@class=\"o-chart-results-list-row-container\"]/ul/li[4]/ul/li[5]/span')\n",
    "for i in peak:\n",
    "    if i.text is None:\n",
    "        Peak.append('-')\n",
    "    else:\n",
    "        Peak.append(i.text)\n",
    "        \n",
    "#Scrapping the data having weeks on board data\n",
    "weeks=driver.find_elements(By.XPATH,'//div[@class=\"o-chart-results-list-row-container\"]/ul/li[4]/ul/li[6]/span')\n",
    "for i in weeks:\n",
    "    if i.text is None:\n",
    "        Weeks_on_board.append('-')\n",
    "    else:\n",
    "        Weeks_on_board.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Last week Rank</th>\n",
       "      <th>Peak Rank</th>\n",
       "      <th>Weeks on board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Texas Hold 'Em</td>\n",
       "      <td>Beyonce</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lovin On Me</td>\n",
       "      <td>Jack Harlow</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lose Control</td>\n",
       "      <td>Teddy Swims</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Carnival</td>\n",
       "      <td>¥$: Kanye West &amp; Ty Dolla $ign Featuring Rich ...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Beautiful Things</td>\n",
       "      <td>Benson Boone</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Talking</td>\n",
       "      <td>¥$: Kanye West &amp; Ty Dolla $ign Featuring North...</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Monaco</td>\n",
       "      <td>Bad Bunny</td>\n",
       "      <td>97</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Where It Ends</td>\n",
       "      <td>Bailey Zimmerman</td>\n",
       "      <td>-</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Wondering Why</td>\n",
       "      <td>The Red Clay Strays</td>\n",
       "      <td>-</td>\n",
       "      <td>71</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Northern Attitude</td>\n",
       "      <td>Noah Kahan With Hozier</td>\n",
       "      <td>75</td>\n",
       "      <td>37</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Song                                             Artist  \\\n",
       "0      Texas Hold 'Em                                            Beyonce   \n",
       "1         Lovin On Me                                        Jack Harlow   \n",
       "2        Lose Control                                        Teddy Swims   \n",
       "3            Carnival  ¥$: Kanye West & Ty Dolla $ign Featuring Rich ...   \n",
       "4    Beautiful Things                                       Benson Boone   \n",
       "..                ...                                                ...   \n",
       "95            Talking  ¥$: Kanye West & Ty Dolla $ign Featuring North...   \n",
       "96             Monaco                                          Bad Bunny   \n",
       "97      Where It Ends                                   Bailey Zimmerman   \n",
       "98      Wondering Why                                The Red Clay Strays   \n",
       "99  Northern Attitude                             Noah Kahan With Hozier   \n",
       "\n",
       "   Last week Rank Peak Rank Weeks on board  \n",
       "0               2         1              2  \n",
       "1               1         1             15  \n",
       "2               5         2             28  \n",
       "3               3         3              2  \n",
       "4               4         3              5  \n",
       "..            ...       ...            ...  \n",
       "95             30        30              2  \n",
       "96             97         5             19  \n",
       "97              -        32              8  \n",
       "98              -        71              8  \n",
       "99             75        37             12  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a dataframe for the scrapped data\n",
    "billboard=pd.DataFrame({'Song':Song,'Artist':Artist,'Last week Rank':Lastweek,'Peak Rank':Peak,'Weeks on board':Weeks_on_board})\n",
    "billboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Closing the driver\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.Scrape the details of Highest selling novels.\n",
    "\n",
    "Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare/\n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "A) Book name\n",
    "\n",
    "B) Author name\n",
    "\n",
    "C) Volumes sold\n",
    "\n",
    "D) Publisher\n",
    "\n",
    "E) Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to web driver\n",
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the website to driver\n",
    "driver.get('https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty lists to store the scrapped data\n",
    "Book=[]\n",
    "Author=[]\n",
    "Volume=[]\n",
    "Publisher=[]\n",
    "Genre=[]\n",
    "\n",
    "#Scrapping the data having the book name\n",
    "book=driver.find_elements(By.XPATH,\"//table[@class='in-article sortable']/tbody/tr/td[2]\")\n",
    "for i in book:\n",
    "    Book.append(i.text)\n",
    "    \n",
    "#Scrapping the data having the author name\n",
    "author=driver.find_elements(By.XPATH,\"//table[@class='in-article sortable']/tbody/tr/td[3]\")\n",
    "for i in author:\n",
    "    Author.append(i.text)\n",
    "    \n",
    "#Scrapping the data having the volumes sold details\n",
    "volume=driver.find_elements(By.XPATH,\"//table[@class='in-article sortable']/tbody/tr/td[4]\")\n",
    "for i in volume:\n",
    "    Volume.append(i.text)\n",
    "\n",
    "#Scrapping the data having publisher details\n",
    "publisher=driver.find_elements(By.XPATH,\"//table[@class='in-article sortable']/tbody/tr/td[5]\")\n",
    "for i in publisher:\n",
    "    Publisher.append(i.text)\n",
    "    \n",
    "#Scrapping the data having genre details \n",
    "genre=driver.find_elements(By.XPATH,\"//table[@class='in-article sortable']/tbody/tr/td[6]\")\n",
    "for i in genre:\n",
    "    Genre.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book</th>\n",
       "      <th>Author</th>\n",
       "      <th>Volumes sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Book            Author  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volumes sold        Publisher                        Genre  \n",
       "0     5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1     4,475,152       Bloomsbury           Children's Fiction  \n",
       "2     4,200,654       Bloomsbury           Children's Fiction  \n",
       "3     4,179,479       Bloomsbury           Children's Fiction  \n",
       "4     3,758,936     Random House              Romance & Sagas  \n",
       "..          ...              ...                          ...  \n",
       "95      807,311     Random House   General & Literary Fiction  \n",
       "96      794,201          Penguin        Food & Drink: General  \n",
       "97      792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98      791,507            Orion           Biography: General  \n",
       "99      791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a dataframe for the scrapped data\n",
    "novels=pd.DataFrame({})\n",
    "novels['Book']=Book\n",
    "novels['Author']=Author\n",
    "novels['Volumes sold']=Volume\n",
    "novels['Publisher']=Publisher\n",
    "novels['Genre']=Genre\n",
    "novels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Closing the driver\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.Scrape the details most watched tv series of all time from imdb.com.\n",
    "\n",
    "Url = https://www.imdb.com/list/ls095964455/\n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "A) Name\n",
    "\n",
    "B) Year span\n",
    "\n",
    "C) Genre\n",
    "\n",
    "D) Run time\n",
    "\n",
    "E) Ratings\n",
    "\n",
    "F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to web driver\n",
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the website to driver\n",
    "driver.get('https://www.imdb.com/list/ls512407256/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty lists for storing the scrapped data\n",
    "Name=[]\n",
    "Year=[]\n",
    "Genre=[]\n",
    "Runtime=[]\n",
    "Rating=[]\n",
    "Vote=[]\n",
    "\n",
    "#Scrapping the data having the series name\n",
    "name=driver.find_elements(By.XPATH,\"//h3[@class='lister-item-header']/a\")\n",
    "for i in name:\n",
    "    Name.append(i.text)\n",
    "    \n",
    "#Scrapping the data having the year span details\n",
    "year=driver.find_elements(By.XPATH,\"//span[@class='lister-item-year text-muted unbold']\")\n",
    "for i in year:\n",
    "    Year.append(i.text)\n",
    "    \n",
    "#Scrapping the data having the genre details\n",
    "genre=driver.find_elements(By.XPATH,\"//span[@class='genre']\")\n",
    "for i in genre:\n",
    "    Genre.append(i.text)\n",
    "    \n",
    "#Scrapping the data having the runtime details\n",
    "runtime=driver.find_elements(By.XPATH,\"//span[@class='runtime']\")\n",
    "for i in runtime:\n",
    "    Runtime.append(i.text)\n",
    "    \n",
    "#Scrapping the data having rating details\n",
    "rating=driver.find_elements(By.XPATH,\"//div[@class='ipl-rating-star small']\")\n",
    "for i in rating:\n",
    "    Rating.append(i.text)\n",
    "    \n",
    "#Scrapping the data having the votes details\n",
    "votes=driver.find_elements(By.XPATH,\"//span[@name='nv']\")\n",
    "for i in votes:\n",
    "    Vote.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>55 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,262,800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016–2025)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,320,628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1,072,383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>313,497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>273,443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>True Detective</td>\n",
       "      <td>(2014– )</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>55 min</td>\n",
       "      <td>8.9</td>\n",
       "      <td>645,889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Teen Wolf</td>\n",
       "      <td>(2011–2017)</td>\n",
       "      <td>Action, Drama, Fantasy</td>\n",
       "      <td>41 min</td>\n",
       "      <td>7.7</td>\n",
       "      <td>162,078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>The OA</td>\n",
       "      <td>(2016–2019)</td>\n",
       "      <td>Drama, Fantasy, Mystery</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>114,895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>The Simpsons</td>\n",
       "      <td>(1989– )</td>\n",
       "      <td>Animation, Comedy</td>\n",
       "      <td>22 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>433,132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Desperate Housewives</td>\n",
       "      <td>(2004–2012)</td>\n",
       "      <td>Comedy, Drama, Mystery</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>138,703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Name    Year span                     Genre Runtime  \\\n",
       "0        Game of Thrones  (2011–2019)  Action, Adventure, Drama  55 min   \n",
       "1        Stranger Things  (2016–2025)    Drama, Fantasy, Horror  51 min   \n",
       "2       The Walking Dead  (2010–2022)   Drama, Horror, Thriller  44 min   \n",
       "3         13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller  60 min   \n",
       "4                The 100  (2014–2020)    Drama, Mystery, Sci-Fi  43 min   \n",
       "..                   ...          ...                       ...     ...   \n",
       "95        True Detective     (2014– )     Crime, Drama, Mystery  55 min   \n",
       "96             Teen Wolf  (2011–2017)    Action, Drama, Fantasy  41 min   \n",
       "97                The OA  (2016–2019)   Drama, Fantasy, Mystery  60 min   \n",
       "98          The Simpsons     (1989– )         Animation, Comedy  22 min   \n",
       "99  Desperate Housewives  (2004–2012)    Comedy, Drama, Mystery  45 min   \n",
       "\n",
       "   Rating      Votes  \n",
       "0     9.2  2,262,800  \n",
       "1     8.7  1,320,628  \n",
       "2     8.1  1,072,383  \n",
       "3     7.5    313,497  \n",
       "4     7.6    273,443  \n",
       "..    ...        ...  \n",
       "95    8.9    645,889  \n",
       "96    7.7    162,078  \n",
       "97    7.8    114,895  \n",
       "98    8.7    433,132  \n",
       "99    7.6    138,703  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a dataframe for the scrapped data\n",
    "IMDB=pd.DataFrame({'Name':Name,'Year span':Year,'Genre':Genre,'Runtime':Runtime,'Rating':Rating,'Votes':Vote})\n",
    "IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Closing the driver\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10.Details of Datasets from UCI machine learning repositories.\n",
    "\n",
    "Url = https://archive.ics.uci.edu/\n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "A) Dataset name\n",
    "\n",
    "B) Data type\n",
    "\n",
    "C) Task\n",
    "\n",
    "D) Attribute type\n",
    "\n",
    "E) No of instances\n",
    "\n",
    "F) No of attribute\n",
    "\n",
    "G) Year\n",
    "\n",
    "Note: - from the home page you have to go to the Show All Dataset page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to web driver\n",
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the website to driver\n",
    "driver.get('https://archive.ics.uci.edu/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on view all datasets link\n",
    "datasets=driver.find_element(By.XPATH,\"/html/body/div/div[1]/div[1]/main/div/div[1]/div/div/div/a[1]\")\n",
    "try:\n",
    "    datasets.click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(datasets.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty lists for storing the scrapped data\n",
    "Name=[]\n",
    "Type=[]\n",
    "Task=[]\n",
    "Attribute=[]\n",
    "No_of_Instance=[]\n",
    "No_of_Attribute=[]\n",
    "\n",
    "#Scrapping the data having dataset name\n",
    "try:\n",
    "    names=driver.find_elements(By.XPATH,'//div[@class=\"relative col-span-8 sm:col-span-7\"]/h2/a')\n",
    "    for i in names:\n",
    "        Name.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Name.append('-')\n",
    "    \n",
    "#Scrapping the data having data type\n",
    "try:\n",
    "    types=driver.find_elements(By.XPATH,'//div[@class=\"my-2 hidden gap-4 md:grid grid-cols-12\"]/div[2]/span')\n",
    "    for i in types:\n",
    "        Type.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Type.append('-')\n",
    "    \n",
    "#Scrapping the data having default task\n",
    "try:\n",
    "    task=driver.find_elements(By.XPATH,'//p[@class=\"truncate\"]')\n",
    "    for i in task:\n",
    "        Task.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Task.append('-')\n",
    "        \n",
    "#Scrapping the data having attribute types\n",
    "try:\n",
    "    attribute=driver.find_elements(By.XPATH,'//div[@class=\"my-2 hidden gap-4 md:grid grid-cols-12\"]/div[4]/span')\n",
    "    for i in attribute:\n",
    "        Attribute.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Attribute.append('-')\n",
    "        \n",
    "#Scrapping the data having no of instances\n",
    "try:\n",
    "    instance=driver.find_elements(By.XPATH,'//div[@class=\"my-2 hidden gap-4 md:grid grid-cols-12\"]/div[3]/span')\n",
    "    for i in instance:\n",
    "        No_of_Instance.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    No_of_Instance.append('-')\n",
    "        \n",
    "#Scrapping the data having no of attributes\n",
    "try:\n",
    "    attribute_no=driver.find_elements(By.XPATH,'//div[@class=\"my-2 hidden gap-4 md:grid grid-cols-12\"]/div[4]/span')\n",
    "    for i in attribute_no:\n",
    "        No_of_Attribute.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    No_of_Attribute.append('-')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Data types</th>\n",
       "      <th>Default Task</th>\n",
       "      <th>Attribute types</th>\n",
       "      <th>No of instances</th>\n",
       "      <th>No of atrributes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iris</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>A small classic dataset from Fisher, 1936. One...</td>\n",
       "      <td>4 Features</td>\n",
       "      <td>150 Instances</td>\n",
       "      <td>4 Features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dry Bean Dataset</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Images of 13,611 grains of 7 different registe...</td>\n",
       "      <td>16 Features</td>\n",
       "      <td>13.61K Instances</td>\n",
       "      <td>16 Features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Heart Disease</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>4 databases: Cleveland, Hungary, Switzerland, ...</td>\n",
       "      <td>13 Features</td>\n",
       "      <td>303 Instances</td>\n",
       "      <td>13 Features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rice (Cammeo and Osmancik)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>A total of 3810 rice grain's images were taken...</td>\n",
       "      <td>7 Features</td>\n",
       "      <td>3.81K Instances</td>\n",
       "      <td>7 Features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Predict whether income exceeds $50K/yr based o...</td>\n",
       "      <td>14 Features</td>\n",
       "      <td>48.84K Instances</td>\n",
       "      <td>14 Features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Raisin</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Images of the Kecimen and Besni raisin varieti...</td>\n",
       "      <td>8 Features</td>\n",
       "      <td>900 Instances</td>\n",
       "      <td>8 Features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Breast Cancer Wisconsin (Diagnostic)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Diagnostic Wisconsin Breast Cancer Database.</td>\n",
       "      <td>30 Features</td>\n",
       "      <td>569 Instances</td>\n",
       "      <td>30 Features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wine</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>Using chemical analysis to determine the origi...</td>\n",
       "      <td>13 Features</td>\n",
       "      <td>178 Instances</td>\n",
       "      <td>13 Features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wine Quality</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Two datasets are included, related to red and ...</td>\n",
       "      <td>12 Features</td>\n",
       "      <td>4.9K Instances</td>\n",
       "      <td>12 Features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Diabetes</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>This diabetes dataset is from AIM '94</td>\n",
       "      <td>20 Features</td>\n",
       "      <td>1 Instances</td>\n",
       "      <td>20 Features</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Name                 Data types  \\\n",
       "0                                  Iris                    Tabular   \n",
       "1                      Dry Bean Dataset               Multivariate   \n",
       "2                         Heart Disease               Multivariate   \n",
       "3            Rice (Cammeo and Osmancik)               Multivariate   \n",
       "4                                 Adult               Multivariate   \n",
       "5                                Raisin               Multivariate   \n",
       "6  Breast Cancer Wisconsin (Diagnostic)               Multivariate   \n",
       "7                                  Wine                    Tabular   \n",
       "8                          Wine Quality               Multivariate   \n",
       "9                              Diabetes  Multivariate, Time-Series   \n",
       "\n",
       "                                        Default Task Attribute types  \\\n",
       "0  A small classic dataset from Fisher, 1936. One...      4 Features   \n",
       "1  Images of 13,611 grains of 7 different registe...     16 Features   \n",
       "2  4 databases: Cleveland, Hungary, Switzerland, ...     13 Features   \n",
       "3  A total of 3810 rice grain's images were taken...      7 Features   \n",
       "4  Predict whether income exceeds $50K/yr based o...     14 Features   \n",
       "5  Images of the Kecimen and Besni raisin varieti...      8 Features   \n",
       "6       Diagnostic Wisconsin Breast Cancer Database.     30 Features   \n",
       "7  Using chemical analysis to determine the origi...     13 Features   \n",
       "8  Two datasets are included, related to red and ...     12 Features   \n",
       "9              This diabetes dataset is from AIM '94     20 Features   \n",
       "\n",
       "    No of instances No of atrributes  \n",
       "0     150 Instances       4 Features  \n",
       "1  13.61K Instances      16 Features  \n",
       "2     303 Instances      13 Features  \n",
       "3   3.81K Instances       7 Features  \n",
       "4  48.84K Instances      14 Features  \n",
       "5     900 Instances       8 Features  \n",
       "6     569 Instances      30 Features  \n",
       "7     178 Instances      13 Features  \n",
       "8    4.9K Instances      12 Features  \n",
       "9       1 Instances      20 Features  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating the dataframe\n",
    "df=pd.DataFrame({\"Name\":Name,\"Data types\":Type,\"Default Task\":Task,\"Attribute types\":Attribute, \n",
    "                 \"No of instances\":No_of_Instance,\"No of atrributes\":No_of_Attribute})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Closing the driver\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
